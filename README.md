<a>
 <img src="https://i.postimg.cc/fy5Nhjk1/gallery.png">
</a>

<h1 align="center">IBM-PROJECT-32197-1660208557 TEAM ID-PNT2022TMID37239</h1>
<h3 align="center">Real-Time Communication System Powered by AI for Specially Abled </h3>
<h4 align="center">TOPIC : REAL TIME COMMUNICATION SYSTEM FOR DIFFERENTLY ABLED</h4>


- TEAM LEADER - **KARTHICK.B**

- TEAM MEMBER - **DEIVENDARAN.S**

- TEAM MEMBER - **SHARUMATHI.KS**

- TEAM MEMBER - **ARJUN ANAND.V**

- TEAM MEMBER - **KRISTEN.M**






<h5 align="center"> Abstract</h5>
Human beings can communicate with one another via natural language channels including words and writing, or through body language (gestures) like hand gestures, head gesticulations, facial expressions, lip motion, and so forth. Learning to read and write in normal language is essential but knowing sign language is equally essential. Individuals who are partially deaf rely on sign language as their primary mode of communication. People who have hearing impairments have difficulty communicating with those who do not have hearing issues if they do not have access to a translator . This is why the deaf community will benefit greatly from a technology that understands sign language especially hand gestures. Even though mobile technology is rapidly evolving and becoming incredible, there has been little technological advancement and development for artificial intelligence voice-based smart devices that can assist deaf people in understanding and responding to their body language. When combined with learning algorithms, ubiquitous sensing may be used to integrate all of the body language information. As with spoken language, body language has a variety of libraries and each communication is distinct . With our technology, each user can program their device to detect and comprehend their hand gestures, allowing it to recognize and interpret those signals into a voice.
<h6 "[https://youtu.be/MI3wwmQlO64](https://www.youtube.com/watch?v=MI3wwmQlO64)"
</h6>
